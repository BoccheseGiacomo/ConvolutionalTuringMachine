# Convolutional Turing Machine (CTM): studying Meta-Learning Emergence from Cellular Automata

## Introduction

The Convolutional Turing Machine (CTM) represents a pioneering step in the exploration of computational models inspired by the complexities and emergent behaviors of cellular automata. Drawing inspiration from Lenia, a cellular automaton known for its rich, lifelike patterns, the CTM seeks to harness the power of convolution operations in a two-dimensional geometric space evolving over time. This project delves into the realm of state space models, aiming to unravel the potential of these systems in simulating, learning, and, ultimately, understanding complex behaviors and algorithms.

## Project Vision and Objectives

CTM is envisioned as a cellular automaton with an inherent capacity for learning and adaptability. Its central goal is to demonstrate the emergence of desired behaviors and to theoretically model any algorithm or function, provided ample space and computation time. The project is anchored in several key objectives:

- **Exploration of Convolutional Dynamics**: Utilizing a convolution kernel, the CTM is an experiment in evolving a system to best associate inputs with outputs, learning from external rewards, and navigating the intricate landscape of state space evolution.
- **Meta-Learning and Beyond**: The model aspires to not only learn but to develop internal learning algorithms, adapting and refining its strategies based on the feedback received. Theoretical considerations suggest the possibility of second-order meta-learning, where the CTM could evolve meta-rewards, guiding itself towards optimal behaviors with increasingly minimal training data.
- **Complex Behavior Simulation**: The kernel of the CTM is analogous to a stencil in differential equations, capable of simulating intricate behaviors akin to those observed in nonlinear partial differential equations. This ability opens the door to modeling complex physical structures, potentially emulating the spatial configurations of neuronal networks.

## Challenges and Training

One of the most intriguing yet challenging aspects of the CTM is its training process. The project steps away from conventional optimization methods used in Artificial Neural Networks (ANNs), such as gradient descent, and instead embraces a more exploratory approach:

- **Genetic Algorithms for Exploration**: Training the CTM is envisioned to rely heavily on genetic algorithms. The focus is on exploration, encouraging a wide variety of policies and behaviors to be experimented with.
- **Complex Training Dynamics**: Given the theoretical capabilities of the CTM, training it to harness these abilities is an ambitious endeavor. The model needs to propagate information effectively, construct complex internal models, and potentially develop its reinforcement learning algorithms.

## Current State and Future Directions

The CTM project is in its nascent stages, with training methodologies and practical applications still under development. The current focus is on understanding the theoretical limits and practical capabilities of the model, particularly in training it to achieve the envisioned emergent behaviors.

## Installation and Usage
The actual setup is manual: you need to clone the repo and go with your python environment.

## Contributions and Collaboration

We welcome contributions and collaborations from researchers, enthusiasts, and anyone interested in exploring the frontiers of cellular automata and state space models. If you have ideas, suggestions, or want to contribute to the project, feel free to reach out or submit a pull request.

## Citation

If you utilize the CTM in your research or projects, kindly cite this work as follows:

```bibtex
@misc{ctm2023,
  author = {Giacomo Bocchese},
  title = {Convolutional Turing Machine: studying Meta-Learning Emergence from Cellular Automata},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/BoccheseGiacomo/ConvolutionalTuringMachine}}
}
```

